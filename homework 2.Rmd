---
title: "homework-2"
author: "Amina Mohammed (17301920), Joost Dijkstra (),Edward Tandia (17310806)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

Updated to do list:

- Ex1 Amina
- Ex2 Ed
- Ex3 Joost

- Make the RMD aesthetic
- Delete useless file and clean the GIT

```{r, echo = FALSE, include = FALSE, message = FALSE}
source(here::here("Setup.R"))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


___Answers of Problem 1___
```{r echo = FALSE, include = FALSE, message = FALSE}
supermarket <- read.csv("supermarket_sales.csv")
unitPrice <- as.matrix(supermarket[,7])

# statistic on the sample 
têta_hat_mean <- mean(unitPrice)       # mean of unit price (theoretical)
têta_hat_median <- median(unitPrice)   # median of unit price (theoretical)
têta_hat_max <- max(unitPrice)         # max of unit price (theoretical)

B <- 1000                     #number of iteration

```
In order to perfom the unbiased estimator of the variance, we're going to need the boostrapped statistic and the data statistic. Let's suppose $\hat{\theta}$ which can be either the mean, median and the maximum of the dataset.

Since Bootstrapping is the process of resampling with replacement, we're going to define the boostraped sample as follow: 


```{r echo = FALSE, include = FALSE, message = FALSE}

tableStatisticalvalue <- data.frame(Statistics= c("mean", "median", "max"), Value=c(têta_hat_mean,têta_hat_median,têta_hat_max))

```
```{r echo=FALSE}
kable(head(tableStatisticalvalue), booktabs = TRUE) %>%
  kable_styling(font_size = 10)
```


**Question 1.** 
```{r echo = FALSE, include = FALSE, message = FALSE}
#Bootstrap with for loop mean
set.seed(123)
têta_hat_loop <- rep(0,B)        #save the unbiased estimator of var

# Bootstrap with a for loop 
for (i in 1:B) {
  
  têta_hat_loop[i] <- mean(sample(unitPrice, replace = TRUE))                      # bootstrap estimate of mean
}

estimator_loop <-(1/(B-1))*(sum(têta_hat_loop- têta_hat_mean)^2)
estimator_loop
```
After loading the dataset `supermarket_sales.csv`. We are interested in the column `Unit.price` where $\hat{\theta}$ is the mean. We used a`for` loop in order to compute the bootstrap and then compute the unbiased estimator of the variance with $B=1'000$ with the help of the following formula: $$\frac{1}{B-1}\sum_{b=1}(\hat{\theta}^\ast_{b}-\hat{\theta})^2.$$
Feel free to observe the code that we did: 

We've decide to fix the set seed for reproducibility at 123, and we find that the unbiased estimator of the variance is  `r estimator_loop`.

<br>

**Question 2. ** 

```{r echo = FALSE, include = FALSE, message = FALSE }
#Bootstrapping without control structure
R=matrix(rep(unitPrice,length(unitPrice)),
         ncol=length(unitPrice),
         byrow=T)
dfUnitePrice <- as.data.frame(t(R))

set.seed(123)                     # Set seed for reproducibility

y <- apply(dfUnitePrice, MARGIN = 2, function(x) sample(x, replace = TRUE, size = length(x)))

teta_hat_noloop <- colMeans(y)

estimator_noloop <-(1/(B-1))*(sum(teta_hat_noloop- têta_hat_mean)^2)
estimator_noloop

```
In question 2, we have proposed an alternative solution without control structure, we have decide to use the to construct a matrix BxB, and finally we apply the function `colMeans()` to have our $\hat{\theta}^\ast_{b}$. In this case too, we've used to fix the set seed for reproducibility, and we find that the unbiased estimator of the variance is  `r estimator_noloop`.
 <br>
 
**Question 3**.  To compare the performances of our solutions at point 1. and point 2. we decide to use two different metrics. In point a, we're profiling our implementation and observe the memory usage and the computation time.
In point b, we're benchmarking our implementation and observe the result that we get.

As a remember, we've as for mean the exact same value either if we use a structure control or not. What could make the difference can be the computation time.
```{r echo = FALSE, include = FALSE, message = FALSE}

tableStatisticalvalue <- data.frame(Statistics= c("mean with control structure", "mean without control structure"), Value=c(estimator_loop,estimator_noloop))

```
```{r echo=FALSE}
kable(head(tableStatisticalvalue), booktabs = TRUE) %>%
  kable_styling(font_size = 10)
```

***a.1. Profiling Bootstrap with for loop***

```{r }
#Profiling Bootstrap with for loop 

set.seed(123)                             # Set seed for reproducibility

profvis::profvis({
têta_hat_loop <- rep(0,B)        #save the unbiased estimator of var

# Bootstrap with a for loop 
for (i in 1:B) {
  
  têta_hat_loop[i] <- mean(sample(unitPrice, replace = TRUE))                      # bootstrap estimate of mean
}

estimator_loop <-(1/(B-1))*(sum(têta_hat_loop- têta_hat_mean)^2)
estimator_loop
 })

```

<br>
<br>

***a.2. Profiling Bootstrap with any control structure ***
```{r }
# Profiling Bootstrap without loop 
set.seed(123)
profvis::profvis({

R=matrix(rep(unitPrice,length(unitPrice)),
         ncol=length(unitPrice),
         byrow=T)
dfUnitePrice <- as.data.frame(t(R))

set.seed(123)                     # Set seed for reproducibility

y <- apply(dfUnitePrice, MARGIN = 2, function(x) sample(x, replace = TRUE, size = length(x)))

teta_hat_noloop <- colMeans(y)

estimator_noloop <-(1/(B-1))*(sum(teta_hat_noloop- têta_hat_mean)^2)
estimator_noloop

  })
```
<br>
<br>

Thus, the memory usage and computation time for the Bootstrap **with control** structure are : <br>
-Memory usage : 12 MB <br>
-Computation time: 160 (ms) <br>

And the memory usage and computation time for Bootstrap **without control** structure are: <br>
-Memory usage : 32.9 MB <br>
-Computation time : 130 (ms) <br>

Based on the profiling, we can see that the the computation time without control structure is lower that the case of using a control structure, however, we use more memory. Thus it's to select between them, we have to do a trade off between memory usage and computation time.
Furthermore, the cache function can help us to reduce the time of computation since it will be computed in the background. 
<br>

<br>
***b. Benchmarking our two implementations. ***
```{r}

microbenchmark::microbenchmark({
  set.seed(123)   
  têta_hat_loop <- rep(0,B)     
  for (i in 1:B) {
  
  têta_hat_loop[i] <- mean(sample(unitPrice, replace = TRUE))               
}

estimator_loop <-(1/(B-1))*(sum(têta_hat_loop- têta_hat_mean)^2)
estimator_loop},

{R=matrix(rep(unitPrice,length(unitPrice)),
         ncol=length(unitPrice),
         byrow=T)
dfUnitePrice <- as.data.frame(t(R))

set.seed(123)                     # Set seed for reproducibility

y <- apply(dfUnitePrice, MARGIN = 2, function(x) sample(x, replace = TRUE, size = length(x)))

teta_hat_noloop <- colMeans(y)

estimator_noloop <-(1/(B-1))*(sum(teta_hat_noloop- têta_hat_mean)^2)
estimator_noloop})

```
We can analyze the benchmarking between the two implementation. Indeed, the microbenchmark package measure the performance of both codes, it also asses and compare the speed of several functions that do the same thing. 

As we can see, we have as an output summary statistics which describing how long the code took to run. This output gives us min, lq, mean, median, uq, and max describing the time it took to run the two function over the 100 iterations of each function call.

When we compare both codes, we can observe that the spreed is larger in the for loop. 

**Question 4.** 

```{r echo = FALSE, include = FALSE, message = FALSE}
#Bootstrap with apply function 
set.seed(123)                        # Set seed for reproducibility
#dfUnitePrice <- as.data.frame(t(R))

y <- apply(dfUnitePrice, MARGIN = 2, function(x) sample(x, replace = TRUE, size = length(x)))

têta_hat_apply <- median(y)

estimator_apply <-(1/(B-1))*(sum(têta_hat_apply- têta_hat_median)^2)
estimator_apply

```
In question 4 we have to compute with $\hat{\theta}$ the *median* as the statistic of interest. In this case we will not either use a any control structures and neither no `colMedians()` or `rowMedians()` functions. Instead, we use the `apply` function and compare the result with the mean that we found

Before anything else, let's remember that The median is sometimes used as opposed to the mean when there are outliers in the sequence that might skew the average of the values.In a normal distribution, the median is the same as the mean and the mode, which is not the case for us. 

Compare to the mean, the median value is `r estimator_apply` which is much lower that the mean which is at `r estimator_loop`. Indeed, if the distribution of data is skewed to the right, the mean is higher than the median. The median can be more descriptive of the data set, here we can understand that most of our data are lower in terms of quantity but there's some high value which make the mean a higher. 


<br>
**Question 5.** 

```{r  echo = FALSE, include = FALSE, message = FALSE }
#Bootstrap with for loop max

set.seed(123)
têta_hat_loop_max <- rep(0,B)        #save the unbiased estimator of var

# Bootstrap with a for loop 
for (i in 1:B) {
  
  têta_hat_loop_max[i] <- max(sample(unitPrice, replace = TRUE))                      # bootstrap estimate of mean
}

estimator_loop_max <-(1/(B-1))*(sum(têta_hat_loop_max- têta_hat_max)^2)
estimator_loop_max
```

In question 5, we use a control structure as we did previously in point 1. Here we're going to repeat with $\hat{\theta}$ the *max* as the statistic of interest and compare it to the mean from point 1.

- Unbiased estimator of var with mean boostraping : `r estimator_loop`
- Unbiased estimator of var with max boostraping : `r estimator_loop_max`

We can observe that we have a decrease on the variance. 

```{r echo = FALSE, include = FALSE, message = FALSE}
df_answer5 <- data.frame (Statistic  = c("mean", "max"),
                  "têta" = c(têta_hat_mean, têta_hat_max),
                  "Unbiased Estimator" = c(estimator_loop,estimator_loop_max)
                  )
```
```{r echo=FALSE}
df_answer5 %>%
  kable(booktabs = TRUE) %>%
  kable_styling(font_size =10)
```